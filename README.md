# KerasResourceScalableCNNs
##Code used for my Master's thesis at the University of California Davis.
##Using the tf.Keras library, this project creates and runs Channel-scaled resource scalable models. Link to full thesis will be published ##upon approval by the university. The abstract for my thesis is below:

State-of-the-art image recognition systems use sophisticated Convolutional Neural Networks (CNNs) that are designed and trained to identify numerous object classes. Inference using such complex networks is fairly resource intensive, prohibiting their deployment on resource-constrained edge devices. In this context, we make two observations: First, the ability to classify an exhaustive list of categories is excessive for the demands of most IoT applications. Furthermore, designing a new custom-designed CNN architecture for each new IoT application is impractical, due to the inherent difficulty in developing competitive models and time-to-market pressure. The observations motivate us to consider if one can utilize an existing structurally-optimized CNN model to automatically construct a competitive CNN for a given IoT application whose objects of interest are a fraction of categories that the original CNN was designed to classify, such that the modelâ€™s inference resource requirement is proportionally scaled down. We use the term \emph{resource scalability} to refer to this concept, and develop a methodology for automated synthesis of resource scalable CNNs from an optimized baseline CNN. The synthesized CNN has sufficient learning capacity for handling the given IoT application requirements, and yields competitive accuracy. The proposed approach is fast, and unlike the presently common practice of CNN design, does not require iterative rounds of training trial and error. Experimental results showcase the efficacy of the approach, and highlight its complementary nature with respect to existing model compression techniques.
